{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import sys\n",
    "from argparse import ArgumentParser\n",
    "import logging\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "from torch.utils import data\n",
    "from torch.nn import functional as fnn\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "TRAIN_SIZE = 0.8\n",
    "NUM_PTS = 971\n",
    "CROP_SIZE = 128\n",
    "SUBMISSION_HEADER = \"file_name,Point_M0_X,Point_M0_Y,Point_M1_X,Point_M1_Y,Point_M2_X,Point_M2_Y,Point_M3_X,Point_M3_Y,Point_M4_X,Point_M4_Y,Point_M5_X,Point_M5_Y,Point_M6_X,Point_M6_Y,Point_M7_X,Point_M7_Y,Point_M8_X,Point_M8_Y,Point_M9_X,Point_M9_Y,Point_M10_X,Point_M10_Y,Point_M11_X,Point_M11_Y,Point_M12_X,Point_M12_Y,Point_M13_X,Point_M13_Y,Point_M14_X,Point_M14_Y,Point_M15_X,Point_M15_Y,Point_M16_X,Point_M16_Y,Point_M17_X,Point_M17_Y,Point_M18_X,Point_M18_Y,Point_M19_X,Point_M19_Y,Point_M20_X,Point_M20_Y,Point_M21_X,Point_M21_Y,Point_M22_X,Point_M22_Y,Point_M23_X,Point_M23_Y,Point_M24_X,Point_M24_Y,Point_M25_X,Point_M25_Y,Point_M26_X,Point_M26_Y,Point_M27_X,Point_M27_Y,Point_M28_X,Point_M28_Y,Point_M29_X,Point_M29_Y\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleMinSideToSize(object):\n",
    "    def __init__(self, size=(CROP_SIZE, CROP_SIZE), elem_name='image'):\n",
    "        self.size = torch.tensor(size, dtype=torch.float)\n",
    "        self.elem_name = elem_name\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        h, w, _ = sample[self.elem_name].shape\n",
    "        if h > w:\n",
    "            f = self.size[0] / w\n",
    "        else:\n",
    "            f = self.size[1] / h\n",
    "\n",
    "        sample[self.elem_name] = cv2.resize(sample[self.elem_name], None, fx=f, fy=f, interpolation=cv2.INTER_AREA)\n",
    "        sample[\"scale_coef\"] = f\n",
    "\n",
    "        if 'landmarks' in sample:\n",
    "            landmarks = sample['landmarks'].reshape(-1, 2).float()\n",
    "            landmarks = landmarks * f\n",
    "            sample['landmarks'] = landmarks.reshape(-1)\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "class CropCenter(object):\n",
    "    def __init__(self, size=128, elem_name='image'):\n",
    "        self.size = size\n",
    "        self.elem_name = elem_name\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        img = sample[self.elem_name]\n",
    "        h, w, _ = img.shape\n",
    "        margin_h = (h - self.size) // 2\n",
    "        margin_w = (w - self.size) // 2\n",
    "        sample[self.elem_name] = img[margin_h:margin_h + self.size, margin_w:margin_w + self.size]\n",
    "        sample[\"crop_margin_x\"] = margin_w\n",
    "        sample[\"crop_margin_y\"] = margin_h\n",
    "\n",
    "        if 'landmarks' in sample:\n",
    "            landmarks = sample['landmarks'].reshape(-1, 2)\n",
    "            landmarks -= torch.tensor((margin_w, margin_h), dtype=landmarks.dtype)[None, :]\n",
    "            sample['landmarks'] = landmarks.reshape(-1)\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "class TransformByKeys(object):\n",
    "    def __init__(self, transform, names):\n",
    "        self.transform = transform\n",
    "        self.names = set(names)\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        for name in self.names:\n",
    "            if name in sample:\n",
    "                sample[name] = self.transform(sample[name])\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "class ThousandLandmarksDataset(data.Dataset):\n",
    "    def __init__(self, transforms, names, landmarks, split=\"train\"):\n",
    "        super(ThousandLandmarksDataset, self).__init__()\n",
    "        self.transforms = transforms\n",
    "        self.image_names = names\n",
    "        if split in (\"train\", \"val\"):\n",
    "            self.landmarks = torch.as_tensor(landmarks)\n",
    "        else:\n",
    "            self.landmarks = None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {}\n",
    "        if self.landmarks is not None:\n",
    "            landmarks = self.landmarks[idx]\n",
    "            sample[\"landmarks\"] = landmarks\n",
    "\n",
    "        image = cv2.imread(self.image_names[idx])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        sample[\"image\"] = image\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            sample = self.transforms(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "    \n",
    "# not correct work\n",
    "#class ThousandLandmarksDataset_Fast(data.Dataset):\n",
    "#    def __init__(self, transforms, names,  landmarks, split=\"train\"):\n",
    "#        super(ThousandLandmarksDataset_Fast, self).__init__()\n",
    "#        \n",
    "#        self.samples=[]\n",
    "#        sample = {}\n",
    "#        \n",
    "#\n",
    "#        if split in (\"train\", \"val\"):\n",
    "#            landmarks = torch.as_tensor(landmarks)\n",
    "#        else:\n",
    "#            landmarks = None\n",
    "#\n",
    "#        if landmarks is not None:\n",
    "#            for idx, name in tqdm(enumerate(names,start=0), desc=\"Prepare data...\"):\n",
    "#                image = cv2.imread(name)\n",
    "#                sample[\"image\"] = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#                landmark = landmarks[idx]\n",
    "#                sample[\"landmarks\"] = landmark\n",
    "#                self.samples.append(transforms(sample))\n",
    "#        else:\n",
    "#            for name in tqdm(names,desc=\"Prepare data...\") :\n",
    "#                image = cv2.imread(name)\n",
    "#                sample[\"image\"] = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#                self.samples.append(transforms(sample))        \n",
    "#\n",
    "#    def __getitem__(self, idx):\n",
    "#        return self.samples[idx]\n",
    "#\n",
    "#    def __len__(self):\n",
    "#        return len(self.samples)\n",
    "\n",
    "\n",
    "def restore_landmarks(landmarks, f, margins):\n",
    "    dx, dy = margins\n",
    "    landmarks[:, 0] += dx\n",
    "    landmarks[:, 1] += dy\n",
    "    landmarks /= f\n",
    "    return landmarks\n",
    "\n",
    "\n",
    "def restore_landmarks_batch(landmarks, fs, margins_x, margins_y):\n",
    "    landmarks[:, :, 0] += margins_x[:, None]\n",
    "    landmarks[:, :, 1] += margins_y[:, None]\n",
    "    landmarks /= fs[:, None, None]\n",
    "    return landmarks\n",
    "\n",
    "\n",
    "def create_submission(path_to_data, test_predictions, path_to_submission_file):\n",
    "    output_file = path_to_submission_file\n",
    "    wf = open(output_file, 'w')\n",
    "    wf.write(SUBMISSION_HEADER)\n",
    "\n",
    "    mapping = pd.read_csv(path_to_data, delimiter='\\t')\n",
    "\n",
    "    for i, row in mapping.iterrows():\n",
    "        file_name = row[0]\n",
    "        point_index_list = np.array(eval(row[1]))\n",
    "        points_for_image = test_predictions[i]\n",
    "        needed_points = points_for_image[point_index_list].astype(np.int)\n",
    "        wf.write(file_name + ',' + ','.join(map(str, needed_points.reshape(2 * len(point_index_list)))) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loaders, loss_fn, optimizer, scheduler, n_epochs, device, labelStr=\"model\", show_plots=True):\n",
    "    since = time.time()\n",
    "    model.to(device)\n",
    "    best_val_loss = np.inf    \n",
    "    \n",
    "    losses = {phase: [] for phase in ['train', 'val']}\n",
    "    \n",
    "    descBatch = {'train':\"training...\",'val':\"validation...\"}\n",
    "    \n",
    "    for epoch in tqdm(range(n_epochs), desc=\"epoch\"):\n",
    "        for phase in ['train', 'val']:            \n",
    "            model.train() if phase == 'train' else model.eval()\n",
    "            loss_history = []\n",
    "            for batch in tqdm(loaders[phase], total=len(loaders[phase]), desc=descBatch[phase]):\n",
    "                images = batch[\"image\"].to(device)  # B x 3 x CROP_SIZE x CROP_SIZE\n",
    "                landmarks = batch[\"landmarks\"]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    pred_landmarks = model(images).cpu() \n",
    "                    loss = loss_fn(pred_landmarks, landmarks, reduction=\"mean\")\n",
    "                    #loss = loss_fn(pred_landmarks, landmarks)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                loss_history.append(loss.item())\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step(loss)\n",
    "                #scheduler.step()\n",
    "            losses[phase].append(np.mean(loss_history))\n",
    "        \n",
    "        # output info and save more success model\n",
    "        if show_plots:\n",
    "            clear_output(True)        \n",
    "            for phase in ['train', 'val']:\n",
    "                plt.plot(losses[phase], label=phase)\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "            for i in range(len(losses['train'])):print(\"Epoch #{:2}:\\ttrain loss: {:5.2}\\tval loss: {:5.2}\\n\".format(i, losses['train'][i], losses['val'][i]))\n",
    "        else:\n",
    "            print(\"Epoch #{:2}:\\ttrain loss: {:5.2}\\tval loss: {:5.2}\\n\".format(i, losses['train'][-1], losses['val'][-1]))\n",
    "        \n",
    "        if losses['val'][-1] < best_val_loss:\n",
    "            best_val_loss = losses['val'][-1] \n",
    "            filename = \"{2}loss_{0}_epoch{1}\".format(labelStr, epoch, losses['val'][-1])\n",
    "            with open(f\"{filename}.pth\", \"wb\") as fp:\n",
    "                torch.save(model.state_dict(), fp)\n",
    "    \n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_val_loss))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    predictions = np.zeros((len(loader.dataset), NUM_PTS, 2))\n",
    "    for i, batch in enumerate(tqdm(loader, total=len(loader), desc=\"test prediction...\")):\n",
    "        images = batch[\"image\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_landmarks = model(images).cpu()\n",
    "        pred_landmarks = pred_landmarks.numpy().reshape((len(pred_landmarks), NUM_PTS, 2))  # B x NUM_PTS x 2\n",
    "\n",
    "        fs = batch[\"scale_coef\"].numpy()  # B\n",
    "        margins_x = batch[\"crop_margin_x\"].numpy()  # B\n",
    "        margins_y = batch[\"crop_margin_y\"].numpy()  # B\n",
    "        prediction = restore_landmarks_batch(pred_landmarks, fs, margins_x, margins_y)  # B x NUM_PTS x 2\n",
    "        predictions[i * loader.batch_size: (i + 1) * loader.batch_size] = prediction\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFO:\\\n",
    "ResNet18 (pretrained on ImageNet). Training takes ~ 15 mins. batch=512 (NVIDIA GTX1060 6GB)\\\n",
    "ResNet101 (pretrained on ImageNet). Training takes ~ x mins. batch=80 (NVIDIA GTX1060 6GB)\\\n",
    "ResNeXT50 (pretrained on ImageNet). Training takes ~ 36 mins  batch=112 (NVIDIA GTX1060 6GB)\\\n",
    "ResNeXT50 (pretrained on ImageNet). Training takes ~ 25 mins  batch=384 (NVIDIA T4 16GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Config model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# указать путь к конвертированным данным\n",
    "pathData=\"\"\n",
    "#pathData = \"C:\\\\Users\\\\Lisen\\\\Desktop\\\\CV\\\\CV_01\\\\data\\\\data\\\\prepare_data_10.0PERCENT\\\\\"\n",
    "\n",
    "batch_size = 384\n",
    "#batch_size = 112\n",
    "epochs = 15\n",
    "learning_rate = 1e-3\n",
    "gpu = True\n",
    "\n",
    "device = torch.device(\"cuda: 0\") if gpu else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentations (Now empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    ScaleMinSideToSize((CROP_SIZE, CROP_SIZE)),\n",
    "    CropCenter(CROP_SIZE),\n",
    "    TransformByKeys(transforms.ToPILImage(), (\"image\",)),\n",
    "    TransformByKeys(transforms.ToTensor(), (\"image\",)),\n",
    "    TransformByKeys(transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]), (\"image\",)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change num_workers from 4 to 0, because windows\n",
    "X_train = np.load(os.path.join(pathData, \"X_train.npy\"))\n",
    "names_train = open(os.path.join(pathData, \"names_train\"), \"r\").read().split('\\n')[:-1]\n",
    "train_dataloader = data.DataLoader(ThousandLandmarksDataset(train_transforms, names_train, X_train, split=\"train\"),\n",
    "                                       batch_size=batch_size,\n",
    "                                       num_workers=0, pin_memory=True,\n",
    "                                       shuffle=True, drop_last=True)\n",
    "#change num_workers from 4 to 0, because windows\n",
    "X_val = np.load(os.path.join(pathData, \"X_val.npy\"))\n",
    "names_val = open(os.path.join(pathData, \"names_val\"), \"r\").read().split('\\n')[:-1]\n",
    "val_dataloader = data.DataLoader(ThousandLandmarksDataset(train_transforms, names_val, X_val, split=\"val\"),\n",
    "                                     batch_size=batch_size,\n",
    "                                     num_workers=0, pin_memory=True,\n",
    "                                     shuffle=False, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stage 1**\\\n",
    "Create model, train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnext50 = models.resnext50_32x4d(pretrained=True)\n",
    "resnext50.fc = nn.Linear(resnext50.fc.in_features, 2 * NUM_PTS, bias=True)\n",
    "\n",
    "loss_fn = fnn.mse_loss\n",
    "optimizer = optim.Adam(resnext50.parameters(), lr=learning_rate, amsgrad=True)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.4, patience=2)\n",
    "\n",
    "resnext50 = train_model(resnext50,{\"train\":train_dataloader,\"val\":val_dataloader,},loss_fn,optimizer, scheduler,epochs,device, \"resnext50__FirstStage\",show_plots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stage 2**\\\n",
    "Refresh learning rate, change  config scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnext50.to(torch.device(\"cpu\"))\n",
    "#del resnext50\n",
    "#del optimizer\n",
    "#del scheduler\n",
    "#del loss_fn\n",
    "#with torch.no_grad():\n",
    "#    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# указать путь к лучшей модели или дообучать последнюю эпоху\n",
    "pathModel = \"\"\n",
    "if pathModel != \"\":\n",
    "    resnext50 = models.resnext50_32x4d(pretrained=True)\n",
    "    resnext50.fc = nn.Linear(model_pred.fc.in_features, 2 * NUM_PTS, bias=True)\n",
    "    resnext50.to(device)\n",
    "    with open(pathModel, \"rb\") as fp:\n",
    "        best_state_dict = torch.load(fp, map_location=\"cpu\")\n",
    "        resnext50.load_state_dict(best_state_dict) \n",
    "\n",
    "loss_fn = fnn.mse_loss\n",
    "optimizer = optim.Adam(resnext50.parameters(), lr=learning_rate, amsgrad=True)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "\n",
    "resnext50 = train_model(resnext50,{\"train\":train_dataloader,\"val\":val_dataloader,},loss_fn,optimizer, scheduler,epochs,device, \"resnext50_SecondStage\",show_plots=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# указать путь к test_points.csv \n",
    "testPoints=\"\"\n",
    "#testPoints = \"C:\\\\Users\\\\Lisen\\\\Desktop\\\\CV\\\\CV_01\\\\data\\\\data\\\\test\\\\test_points.csv\"\n",
    "\n",
    "# указать путь к лучшей модели или дообучать последнюю эпоху\n",
    "pathModel = \"\"\n",
    "if pathModel != \"\":\n",
    "    resnext50 = models.resnext50_32x4d(pretrained=True)\n",
    "    resnext50.fc = nn.Linear(model_pred.fc.in_features, 2 * NUM_PTS, bias=True)\n",
    "    resnext50.to(device)\n",
    "    with open(pathModel, \"rb\") as fp:\n",
    "        best_state_dict = torch.load(fp, map_location=\"cpu\")\n",
    "        resnext50.load_state_dict(best_state_dict)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# load test\n",
    "names_test = open(os.path.join(pathData, \"names_test\"), \"r\").read().split('\\n')[:-1]\n",
    "test_dataloader = data.DataLoader(ThousandLandmarksDataset(train_transforms, names_test, None, split=\"test\"),\n",
    "                                      batch_size=batch_size, num_workers=0, pin_memory=True,\n",
    "                                      shuffle=False, drop_last=False)\n",
    "\n",
    "\n",
    "test_predictions = predict(resnext50, test_dataloader, device)\n",
    "create_submission(testPoints, test_predictions, \"resnext50_submit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Watch result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_IMAGES_TO_SHOW = 16\n",
    "NUM_COLS = 4\n",
    "NUM_ROWS = NUM_IMAGES_TO_SHOW // NUM_COLS + int(NUM_IMAGES_TO_SHOW % NUM_COLS != 0)\n",
    "\n",
    "def draw_landmarks(image, landmarks):\n",
    "    for point in landmarks:\n",
    "        x, y = point.astype(np.int)\n",
    "        cv2.circle(image, (x, y), 1, (128, 0, 128), 1, -1)\n",
    "    return image\n",
    "\n",
    "if len(names_test) < NUM_IMAGES_TO_SHOW:\n",
    "    raise RuntimeError(f\"Choose less images to show, you have only {len(names_test)}\")\n",
    "    \n",
    "    \n",
    "random_idxs = np.random.choice(len(names_test), size=min(NUM_IMAGES_TO_SHOW, len(names_test)), replace=False)\n",
    "\n",
    "plt.figure(figsize=(25, NUM_ROWS * 8))\n",
    "for i, idx in enumerate(random_idxs, 1):\n",
    "    image = cv2.imread(names_test[idx])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = draw_landmarks(image, test_predictions[idx])\n",
    "    \n",
    "    plt.subplot(NUM_ROWS, NUM_COLS, i)\n",
    "    plt.imshow(image)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
